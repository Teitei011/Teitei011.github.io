{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disabled-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "objective-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"brazil/\"\n",
    "FILE_NAME = \"Brazil.csv\"\n",
    "\n",
    "\n",
    "tempo_inicial = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "headed-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractDataframeByName(dataframe, location):\n",
    "    print(\"Processing... 0%\")\n",
    "    all_names = dataframe[location].unique().tolist()\n",
    "\n",
    "    number_of_names = len(all_names)\n",
    "    counter = 0\n",
    "\n",
    "    for name in all_names:\n",
    "        counter += 1\n",
    "\n",
    "        #print(\"Processing... {}  - {:.2f}%\".format(name, (counter*100)/number_of_names))\n",
    "        if (counter % 530 == 0):\n",
    "            print(\"Processing... {:.0f}% \".format(\n",
    "                (counter*100)/number_of_names))\n",
    "\n",
    "        newDataframe = dataframe.loc[dataframe[location] == name]\n",
    "        newDataframe.drop(newDataframe.index[0])\n",
    "        newDataframe.reset_index(inplace=True)\n",
    "\n",
    "        newDataframe.to_csv(f\"{PATH}/{name}.csv\", index=False)\n",
    "\n",
    "        #newDataframe.to_json(f\"{PATH}/{name}.json\", orient ='values')\n",
    "\n",
    "\n",
    "def divideByTwoWhenPossible(array):\n",
    "    for i in range(len(array)):\n",
    "        try:\n",
    "            array[i] = array[i] / 2\n",
    "        except:\n",
    "            pass\n",
    "    return array\n",
    "\n",
    "\n",
    "def changeDateOrder(array):\n",
    "    newArray = []\n",
    "    for date in array:\n",
    "        buffer = date.split(\"-\")\n",
    "        newArray.append(buffer[2] + \"-\" + buffer[1] + \"-\" + buffer[0])\n",
    "    return newArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outstanding-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe2Something(dataframe, name):\n",
    "    dataframe.data = [str(dataframe.data[i]).replace(\"/\", \"-\")\n",
    "                      for i in range(len(dataframe))]\n",
    "    if (name == \"estado\"):\n",
    "        newDataframe = dataframe.groupby([name, \"data\"])[\n",
    "            ['casosAcumulado', 'casosNovos', 'obitosAcumulado', 'obitosNovos']].sum().apply(lambda x: divideByTwoWhenPossible(x))\n",
    "\n",
    "\n",
    "    elif (name == \"Brasil\"):\n",
    "        dataframe = dataframe.loc[dataframe[\"regiao\"] == \"Brasil\"]\n",
    "        newDataframe = dataframe[[\"data\", \"casosAcumulado\",\n",
    "                                  \"casosNovos\", \"obitosAcumulado\", \"obitosNovos\"]].copy()\n",
    "\n",
    "    else:  # Municipios\n",
    "        newDataframe = dataframe.groupby([name, \"data\"])[\n",
    "            ['casosAcumulado', 'casosNovos', 'obitosAcumulado', 'obitosNovos']].sum()\n",
    "\n",
    "    newDataframe.reset_index(inplace=True)\n",
    "    newDataframe[\"daily_cases_moving_average\"] = newDataframe['casosNovos'].rolling(\n",
    "        window=7).mean()\n",
    "    newDataframe[\"daily_deaths_moving_average\"] = newDataframe['obitosNovos'].rolling(\n",
    "        window=7).mean()\n",
    "    newDataframe[\"sum_of_daily_cases_week\"] = newDataframe['casosNovos'].rolling(\n",
    "        window=7).sum()\n",
    "    newDataframe[\"sum_of_daily_deaths_week\"] = newDataframe['obitosNovos'].rolling(\n",
    "        window=7).sum()\n",
    "\n",
    "    return newDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "closed-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... 0%\n",
      "Processing... 10% \n",
      "Processing... 20% \n",
      "Processing... 30% \n",
      "Processing... 40% \n",
      "Processing... 50% \n",
      "Processing... 60% \n",
      "Processing... 70% \n",
      "Processing... 80% \n",
      "Processing... 90% \n",
      "Processing... 0%\n",
      "It took 19.69 minutes\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # def pre_processing_csv_data(file_name):\n",
    "    unprocessedDataset = pd.read_csv(\n",
    "        str(FILE_NAME), delimiter=\";\", error_bad_lines=False)\n",
    "\n",
    "    cities = splitDataframe2Something(unprocessedDataset, \"municipio\")\n",
    "    states = splitDataframe2Something(unprocessedDataset, \"estado\")\n",
    "    states[\"estado\"] = states[\"estado\"].replace(['AC', 'AL', \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"], [\"Acre\", \"Alagoas\", \"Amapá\", \"Amazonas\", \"Bahia\", \"Ceará\", \"Distrito Federal\",\n",
    "                                                                \"Espírito Santo\", \"Goiás\", \"Maranhão\",  \"Mato Grosso\", \"Mato Grosso do Sul\", \"Minas Gerais\", \"Pará\", \"Paraíba\", \"Paraná\", \"Pernambuco\", \"Piauí\", \"Rio de Janeiro\", \"Rio Grande do Norte\", \"Rio Grande do Sul\", \"Rondônia\", \"Roraima\", \"Santa Catarina\", \"São Paulo\", \"Sergipe\", \"Tocantins\"])\n",
    "#     print(states)\n",
    "\n",
    "    brazil = splitDataframe2Something(unprocessedDataset, \"Brasil\")\n",
    "    brazil.to_csv(f\"{PATH}/Brasil.csv\", index=False)\n",
    "\n",
    "    #brazil[\"data\"] = changeDateOrder(brazil[\"data\"])\n",
    "    #brazil.to_json(f\"{PATH}/Brasil.json\", orient ='values')\n",
    "\n",
    "    extractDataframeByName(cities, \"municipio\")\n",
    "    extractDataframeByName(states, \"estado\")\n",
    "\n",
    "    print(\"It took {:.2f} minutes\".format((time.time() - tempo_inicial)/60))\n",
    "\n",
    "    os.system(\"rm Brazil.csv\")\n",
    "    os.system(\"./upload2TheCloud.sh\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-electronics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
